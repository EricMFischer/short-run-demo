{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "short_run_demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5eNhP+Khz+wUk3NIPbQaW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricMFischer/short_run_demo/blob/master/short_run_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb8tycQXHYSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "ff7c8a86-8f52-46c7-97e3-91b52449d32d"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBn7rmQ7Hux8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "416692ba-2401-4e68-af2a-556fe8ccb317"
      },
      "source": [
        "# %cd gdrive/My Drive/short_run_demo_folder"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/short_run_demo_folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSvwChstH0z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "3e5b4cad-873c-437c-8ff5-2e2055f8722b"
      },
      "source": [
        "# ! git clone https://github.com/EricMFischer/short_run_demo.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'short_run_demo'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 28 (delta 13), reused 25 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFbimiiLJjM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(‘/content/gdrive’)\n",
        "%cd gdrive/My Drive/short_run_demo_folder/short_run_demo\n",
        "# ! git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrDfSgO2IKaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! pip install torch==1.3.0\n",
        "# ! pip install torchvision==0.4.0\n",
        "# ! pip install matplotlib\n",
        "# ! pip install numpy\n",
        "# ! pip install scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTlGSqYqIQLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utils.py\n",
        "\n",
        "# download Oxford Flowers 102, plotting functions, and toy dataset\n",
        "\n",
        "import torch as t\n",
        "import torchvision as tv\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "##########################\n",
        "# ## DOWNLOAD FLOWERS ## #\n",
        "##########################\n",
        "# Code with minor modification from https://github.com/microsoft/CNTK/tree/master/Examples/Image/DataSets/Flowers\n",
        "# Original Version: Copyright (c) Microsoft Corporation\n",
        "\n",
        "def download_flowers_data():\n",
        "    import tarfile\n",
        "    try:\n",
        "        from urllib.request import urlretrieve\n",
        "    except ImportError:\n",
        "        from urllib import urlretrieve\n",
        "\n",
        "    dataset_folder = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data/flowers/')\n",
        "    if not os.path.exists(os.path.join(dataset_folder, \"jpg\")):\n",
        "        if not os.path.exists(dataset_folder):\n",
        "            os.makedirs(dataset_folder)\n",
        "        print('Downloading data from http://www.robots.ox.ac.uk/~vgg/data/flowers/102/ ...')\n",
        "        tar_filename = os.path.join(dataset_folder, \"102flowers.tgz\")\n",
        "        if not os.path.exists(tar_filename):\n",
        "            urlretrieve(\"http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\", tar_filename)\n",
        "\n",
        "        # extract flower images from tar file\n",
        "        print('Extracting ' + tar_filename + '...')\n",
        "        tarfile.open(tar_filename).extractall(path=dataset_folder)\n",
        "\n",
        "        # clean up\n",
        "        os.remove(tar_filename)\n",
        "        print('Done.')\n",
        "    else:\n",
        "        print('Data available at ' + dataset_folder)\n",
        "\n",
        "\n",
        "##################\n",
        "# ## PLOTTING ## #\n",
        "##################\n",
        "\n",
        "# visualize negative samples synthesized from energy\n",
        "def plot_ims(p, x): tv.utils.save_image(t.clamp(x, -1., 1.), p, normalize=True, nrow=int(x.shape[0] ** 0.5))\n",
        "\n",
        "# plot diagnostics for learning\n",
        "def plot_diagnostics(batch, en_diffs, grad_mags, exp_dir, fontsize=10):\n",
        "    # axis tick size\n",
        "    matplotlib.rc('xtick', labelsize=6)\n",
        "    matplotlib.rc('ytick', labelsize=6)\n",
        "    fig = plt.figure()\n",
        "\n",
        "    def plot_en_diff_and_grad_mag():\n",
        "        # energy difference\n",
        "        ax = fig.add_subplot(221)\n",
        "        ax.plot(en_diffs[0:(batch+1)].data.cpu().numpy())\n",
        "        ax.axhline(y=0, ls='--', c='k')\n",
        "        ax.set_title('Energy Difference', fontsize=fontsize)\n",
        "        ax.set_xlabel('batch', fontsize=fontsize)\n",
        "        ax.set_ylabel('$d_{s_t}$', fontsize=fontsize)\n",
        "        # mean langevin gradient\n",
        "        ax = fig.add_subplot(222)\n",
        "        ax.plot(grad_mags[0:(batch+1)].data.cpu().numpy())\n",
        "        ax.set_title('Average Langevin Gradient Magnitude', fontsize=fontsize)\n",
        "        ax.set_xlabel('batch', fontsize=fontsize)\n",
        "        ax.set_ylabel('$r_{s_t}$', fontsize=fontsize)\n",
        "\n",
        "    def plot_crosscorr_and_autocorr(t_gap_max=2000, max_lag=15, b_w=0.35):\n",
        "        t_init = max(0, batch + 1 - t_gap_max)\n",
        "        t_end = batch + 1\n",
        "        t_gap = t_end - t_init\n",
        "        max_lag = min(max_lag, t_gap - 1)\n",
        "        # rescale energy diffs to unit mean square but leave uncentered\n",
        "        en_rescale = en_diffs[t_init:t_end] / t.sqrt(t.sum(en_diffs[t_init:t_end] * en_diffs[t_init:t_end])/(t_gap-1))\n",
        "        # normalize gradient magnitudes\n",
        "        grad_rescale = (grad_mags[t_init:t_end]-t.mean(grad_mags[t_init:t_end]))/t.std(grad_mags[t_init:t_end])\n",
        "        # cross-correlation and auto-correlations\n",
        "        cross_corr = np.correlate(en_rescale.cpu().numpy(), grad_rescale.cpu().numpy(), 'full') / (t_gap - 1)\n",
        "        en_acorr = np.correlate(en_rescale.cpu().numpy(), en_rescale.cpu().numpy(), 'full') / (t_gap - 1)\n",
        "        grad_acorr = np.correlate(grad_rescale.cpu().numpy(), grad_rescale.cpu().numpy(), 'full') / (t_gap - 1)\n",
        "        # x values and indices for plotting\n",
        "        x_corr = np.linspace(-max_lag, max_lag, 2 * max_lag + 1)\n",
        "        x_acorr = np.linspace(0, max_lag, max_lag + 1)\n",
        "        t_0_corr = int((len(cross_corr) - 1) / 2 - max_lag)\n",
        "        t_0_acorr = int((len(cross_corr) - 1) / 2)\n",
        "\n",
        "        # plot cross-correlation\n",
        "        ax = fig.add_subplot(223)\n",
        "        ax.bar(x_corr, cross_corr[t_0_corr:(t_0_corr + 2 * max_lag + 1)])\n",
        "        ax.axhline(y=0, ls='--', c='k')\n",
        "        ax.set_title('Cross Correlation of Energy Difference\\nand Gradient Magnitude', fontsize=fontsize)\n",
        "        ax.set_xlabel('lag', fontsize=fontsize)\n",
        "        ax.set_ylabel('correlation', fontsize=fontsize)\n",
        "        # plot auto-correlation\n",
        "        ax = fig.add_subplot(224)\n",
        "        ax.bar(x_acorr-b_w/2, en_acorr[t_0_acorr:(t_0_acorr + max_lag + 1)], b_w, label='en. diff. $d_{s_t}$')\n",
        "        ax.bar(x_acorr+b_w/2, grad_acorr[t_0_acorr:(t_0_acorr + max_lag + 1)], b_w, label='grad. mag. $r_{s_t}}$')\n",
        "        ax.axhline(y=0, ls='--', c='k')\n",
        "        ax.set_title('Auto-Correlation of Energy Difference\\nand Gradient Magnitude', fontsize=fontsize)\n",
        "        ax.set_xlabel('lag', fontsize=fontsize)\n",
        "        ax.set_ylabel('correlation', fontsize=fontsize)\n",
        "        ax.legend(loc='upper right', fontsize=fontsize-4)\n",
        "\n",
        "    # make diagnostic plots\n",
        "    plot_en_diff_and_grad_mag()\n",
        "    plot_crosscorr_and_autocorr()\n",
        "    # save figure\n",
        "    plt.subplots_adjust(hspace=0.6, wspace=0.6)\n",
        "    plt.savefig(os.path.join(exp_dir, 'diagnosis_plot.pdf'), format='pdf')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "#####################\n",
        "# ## TOY DATASET ## #\n",
        "#####################\n",
        "\n",
        "class ToyDataset:\n",
        "    def __init__(self, toy_type='gmm', toy_groups=8, toy_sd=0.15, toy_radius=1, viz_res=500, kde_bw=0.05):\n",
        "        # import helper functions\n",
        "        from scipy.stats import gaussian_kde\n",
        "        from scipy.stats import multivariate_normal\n",
        "        self.gaussian_kde = gaussian_kde\n",
        "        self.mvn = multivariate_normal\n",
        "\n",
        "        # toy dataset parameters\n",
        "        self.toy_type = toy_type\n",
        "        self.toy_groups = toy_groups\n",
        "        self.toy_sd = toy_sd\n",
        "        self.toy_radius = toy_radius\n",
        "        self.weights = np.ones(toy_groups) / toy_groups\n",
        "        if toy_type == 'gmm':\n",
        "            means_x = np.cos(2*np.pi*np.linspace(0, (toy_groups-1)/toy_groups, toy_groups)).reshape(toy_groups, 1, 1, 1)\n",
        "            means_y = np.sin(2*np.pi*np.linspace(0, (toy_groups-1)/toy_groups, toy_groups)).reshape(toy_groups, 1, 1, 1)\n",
        "            self.means = toy_radius * np.concatenate((means_x, means_y), axis=1)\n",
        "        else:\n",
        "            self.means = None\n",
        "\n",
        "        # ground truth density\n",
        "        if self.toy_type == 'gmm':\n",
        "            def true_density(x):\n",
        "                density = 0\n",
        "                for k in range(toy_groups):\n",
        "                    density += self.weights[k]*self.mvn.pdf(np.array([x[0], x[1]]), mean=self.means[k].squeeze(),\n",
        "                                                            cov=(self.toy_sd**2)*np.eye(2))\n",
        "                return density\n",
        "        elif self.toy_type == 'rings':\n",
        "            def true_density(x):\n",
        "                radius = np.sqrt((x[0] ** 2) + (x[1] ** 2))\n",
        "                density = 0\n",
        "                for k in range(toy_groups):\n",
        "                    density += self.weights[k] * self.mvn.pdf(radius, mean=self.toy_radius * (k + 1),\n",
        "                                                              cov=(self.toy_sd**2))/(2*np.pi*self.toy_radius*(k+1))\n",
        "                return density\n",
        "        else:\n",
        "            raise RuntimeError('Invalid option for toy_type (use \"gmm\" or \"rings\")')\n",
        "        self.true_density = true_density\n",
        "\n",
        "        # viz parameters\n",
        "        self.viz_res = viz_res\n",
        "        self.kde_bw = kde_bw\n",
        "        if toy_type == 'rings':\n",
        "            self.plot_val_max = toy_groups * toy_radius + 4 * toy_sd\n",
        "        else:\n",
        "            self.plot_val_max = toy_radius + 4 * toy_sd\n",
        "\n",
        "        # save values for plotting groundtruth landscape\n",
        "        self.xy_plot = np.linspace(-self.plot_val_max, self.plot_val_max, self.viz_res)\n",
        "        self.z_true_density = np.zeros(self.viz_res**2).reshape(self.viz_res, self.viz_res)\n",
        "        for x_ind in range(len(self.xy_plot)):\n",
        "            for y_ind in range(len(self.xy_plot)):\n",
        "                self.z_true_density[x_ind, y_ind] = self.true_density([self.xy_plot[x_ind], self.xy_plot[y_ind]])\n",
        "\n",
        "    def sample_toy_data(self, num_samples):\n",
        "        toy_sample = np.zeros(0).reshape(0, 2, 1, 1)\n",
        "        sample_group_sz = np.random.multinomial(num_samples, self.weights)\n",
        "        if self.toy_type == 'gmm':\n",
        "            for i in range(self.toy_groups):\n",
        "                sample_group = self.means[i] + self.toy_sd * np.random.randn(2*sample_group_sz[i]).reshape(-1, 2, 1, 1)\n",
        "                toy_sample = np.concatenate((toy_sample, sample_group), axis=0)\n",
        "        elif self.toy_type == 'rings':\n",
        "            for i in range(self.toy_groups):\n",
        "                sample_radii = self.toy_radius*(i+1) + self.toy_sd * np.random.randn(sample_group_sz[i])\n",
        "                sample_thetas = 2 * np.pi * np.random.random(sample_group_sz[i])\n",
        "                sample_x = sample_radii.reshape(-1, 1) * np.cos(sample_thetas).reshape(-1, 1)\n",
        "                sample_y = sample_radii.reshape(-1, 1) * np.sin(sample_thetas).reshape(-1, 1)\n",
        "                sample_group = np.concatenate((sample_x, sample_y), axis=1)\n",
        "                toy_sample = np.concatenate((toy_sample, sample_group.reshape(-1, 2, 1, 1)), axis=0)\n",
        "        else:\n",
        "            raise RuntimeError('Invalid option for toy_type (\"gmm\" or \"rings\")')\n",
        "\n",
        "        return toy_sample\n",
        "\n",
        "    def plot_toy_density(self, plot_truth=False, f=None, epsilon=0.0, x_s_t=None, save_path='toy.pdf'):\n",
        "        num_plots = 0\n",
        "        if plot_truth:\n",
        "            num_plots += 1\n",
        "\n",
        "        # density of learned EBM\n",
        "        if f is not None:\n",
        "            num_plots += 1\n",
        "            xy_plot_torch = t.Tensor(self.xy_plot).view(-1, 1, 1, 1).to(next(f.parameters()).device)\n",
        "            # y values for learned energy landscape of descriptor network\n",
        "            z_learned_energy = np.zeros([self.viz_res, self.viz_res])\n",
        "            for i in range(len(self.xy_plot)):\n",
        "                y_vals = float(self.xy_plot[i]) * t.ones_like(xy_plot_torch)\n",
        "                vals = t.cat((xy_plot_torch, y_vals), 1)\n",
        "                z_learned_energy[i] = f(vals).data.cpu().numpy()\n",
        "            # rescale y values to correspond to the groundtruth temperature\n",
        "            if epsilon > 0:\n",
        "                z_learned_energy *= 2 / (epsilon ** 2)\n",
        "\n",
        "            # transform learned energy into learned density\n",
        "            z_learned_density_unnormalized = np.exp(- z_learned_energy)\n",
        "            bin_area = (self.xy_plot[1] - self.xy_plot[0]) ** 2\n",
        "            z_learned_density = z_learned_density_unnormalized / (bin_area * np.sum(z_learned_density_unnormalized))\n",
        "\n",
        "        # kernel density estimate of shortrun samples\n",
        "        if x_s_t is not None:\n",
        "            num_plots += 1\n",
        "            density_estimate = self.gaussian_kde(x_s_t.squeeze().cpu().numpy().transpose(), bw_method=self.kde_bw)\n",
        "            z_kde_density = np.zeros([self.viz_res, self.viz_res])\n",
        "            for i in range(len(self.xy_plot)):\n",
        "                for j in range(len(self.xy_plot)):\n",
        "                    z_kde_density[i, j] = density_estimate((self.xy_plot[j], self.xy_plot[i]))\n",
        "\n",
        "        # plot results\n",
        "        plot_ind = 0\n",
        "        fig = plt.figure()\n",
        "\n",
        "        # true density\n",
        "        if plot_truth:\n",
        "            plot_ind += 1\n",
        "            ax = fig.add_subplot(2, num_plots, plot_ind)\n",
        "            ax.set_title('True density')\n",
        "            plt.imshow(self.z_true_density, cmap='viridis')\n",
        "            plt.axis('off')\n",
        "            ax = fig.add_subplot(2, num_plots, plot_ind + num_plots)\n",
        "            ax.set_title('True log-density')\n",
        "            plt.imshow(np.log(self.z_true_density + 1e-10), cmap='viridis')\n",
        "            plt.axis('off')\n",
        "        # learned ebm\n",
        "        if f is not None:\n",
        "            plot_ind += 1\n",
        "            ax = fig.add_subplot(2, num_plots, plot_ind)\n",
        "            ax.set_title('EBM density')\n",
        "            plt.imshow(z_learned_density, cmap='viridis')\n",
        "            plt.axis('off')\n",
        "            ax = fig.add_subplot(2, num_plots, plot_ind + num_plots)\n",
        "            ax.set_title('EBM log-density')\n",
        "            plt.imshow(np.log(z_learned_density + 1e-10), cmap='viridis')\n",
        "            plt.axis('off')\n",
        "        # shortrun kde\n",
        "        if x_s_t is not None:\n",
        "            plot_ind += 1\n",
        "            ax = fig.add_subplot(2, num_plots, plot_ind)\n",
        "            ax.set_title('Short-run KDE')\n",
        "            plt.imshow(z_kde_density, cmap='viridis')\n",
        "            plt.axis('off')\n",
        "            ax = fig.add_subplot(2, num_plots, plot_ind + num_plots)\n",
        "            ax.set_title('Short-run log-KDE')\n",
        "            plt.imshow(np.log(z_kde_density + 1e-10), cmap='viridis')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, bbox_inches='tight', format='pdf')\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CghBuzt6JBsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nets.py\n",
        "\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "#################################\n",
        "# ## TOY NETWORK FOR 2D DATA ## #\n",
        "#################################\n",
        "\n",
        "class ToyNet(nn.Module):\n",
        "    def __init__(self, dim=2, n_f=32, leak=0.05):\n",
        "        super(ToyNet, self).__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Conv2d(dim, n_f, 1, 1, 0),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f, n_f * 2, 1, 1, 0),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f * 2, n_f * 2, 1, 1, 0),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f * 2, n_f * 2, 1, 1, 0),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f * 2, 1, 1, 1, 0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.f(x).squeeze()\n",
        "\n",
        "\n",
        "#########################\n",
        "# ## VANILLA CONVNET ## #\n",
        "#########################\n",
        "\n",
        "class VanillaNet(nn.Module):\n",
        "    def __init__(self, n_c=3, n_f=32, leak=0.05):\n",
        "        super(VanillaNet, self).__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Conv2d(n_c, n_f, 3, 1, 1),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f, n_f * 2, 4, 2, 1),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f*2, n_f*4, 4, 2, 1),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f*4, n_f*8, 4, 2, 1),\n",
        "            nn.LeakyReLU(leak),\n",
        "            nn.Conv2d(n_f*8, 1, 4, 1, 0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.f(x).squeeze()\n",
        "\n",
        "\n",
        "######################\n",
        "# ## NONLOCAL NET ## #\n",
        "######################\n",
        "# implementation with minor changes from https://github.com/AlexHex7/Non-local_pytorch\n",
        "# Original Version: Copyright (c) 2018 AlexHex7\n",
        "\n",
        "class NonlocalNet(nn.Module):\n",
        "    def __init__(self, n_c=3, n_f=32, leak=0.05):\n",
        "        super(NonlocalNet, self).__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=n_c, out_channels=n_f, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=leak),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            NonLocalBlock(in_channels=n_f),\n",
        "            nn.Conv2d(in_channels=n_f, out_channels=n_f * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=leak),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            NonLocalBlock(in_channels=n_f * 2),\n",
        "            nn.Conv2d(in_channels=n_f * 2, out_channels=n_f * 4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(negative_slope=leak),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=(n_f * 4) * 4 * 4, out_features=n_f * 8),\n",
        "            nn.LeakyReLU(negative_slope=leak),\n",
        "            nn.Linear(in_features=n_f * 8, out_features=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.convs(x).view(x.shape[0], -1)\n",
        "        return self.fc(conv_out).squeeze()\n",
        "\n",
        "# structure of non-local block (from Non-Local Neural Networks https://arxiv.org/abs/1711.07971)\n",
        "class NonLocalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, sub_sample=True):\n",
        "        super(NonLocalBlock, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.inter_channels = max(1, in_channels // 2)\n",
        "\n",
        "        self.g = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                           kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.W = nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                           kernel_size=1, stride=1, padding=0)\n",
        "        nn.init.constant_(self.W.weight, 0)\n",
        "        nn.init.constant_(self.W.bias, 0)\n",
        "        self.theta = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                               kernel_size=1, stride=1, padding=0)\n",
        "        self.phi = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if sub_sample:\n",
        "            self.g = nn.Sequential(self.g, nn.MaxPool2d(kernel_size=(2, 2)))\n",
        "            self.phi = nn.Sequential(self.phi, nn.MaxPool2d(kernel_size=(2, 2)))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
        "        g_x = g_x.permute(0, 2, 1)\n",
        "\n",
        "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
        "        theta_x = theta_x.permute(0, 2, 1)\n",
        "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
        "        f = t.matmul(theta_x, phi_x)\n",
        "        f_div_c = F.softmax(f, dim=-1)\n",
        "\n",
        "        y = t.matmul(f_div_c, g_x)\n",
        "        y = y.permute(0, 2, 1).contiguous()\n",
        "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
        "        w_y = self.W(y)\n",
        "        z = w_y + x\n",
        "\n",
        "        return z\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qMSwNUUJQNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}